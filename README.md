# API de Autos de Infra√ß√£o Ambiental - IBAMA

![Status](https://img.shields.io/badge/status-em%20desenvolvimento-yellow)
![Python](https://img.shields.io/badge/Python-3.11+-blue?logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-blue?logo=fastapi)
![SQLAlchemy](https://img.shields.io/badge/SQLAlchemy-2.0-blue?logo=sqlalchemy)
![MySQL](https://img.shields.io/badge/MySQL-8.0-blue?logo=mysql)
![Docker](https://img.shields.io/badge/Docker-blue?logo=docker)

## üáßüá∑ Sobre o Projeto

A **API IBAMA** √© uma solu√ß√£o de backend robusta e de alta performance, projetada para a ingest√£o, processamento e consulta de dados p√∫blicos sobre autos de infra√ß√£o ambiental emitidos pelo IBAMA. O principal desafio deste projeto √© o processamento eficiente de arquivos CSV de m√∫ltiplos gigabytes, garantindo que os dados sejam validados, processados e armazenados de forma ass√≠ncrona, sem impactar a disponibilidade da API.

Este projeto foi constru√≠do utilizando as mais modernas ferramentas do ecossistema Python, com uma arquitetura **"Async-First"** (totalmente ass√≠ncrona) e foco em boas pr√°ticas de desenvolvimento, escalabilidade e manutenibilidade.

---

## üóÉÔ∏è Fonte dos Dados

A API consome os dados p√∫blicos de autos de infra√ß√£o e san√ß√µes ambientais, que s√£o abertamente disponibilizados pelo IBAMA atrav√©s do Portal de Dados Abertos do Governo Federal.

Os conjuntos de dados originais, em formato CSV, que servem de insumo para a funcionalidade de ingest√£o desta API podem ser encontrados e baixados no seguinte link:

* **Link Oficial:** [**Fiscaliza√ß√£o - Auto de Infra√ß√£o**](https://dados.gov.br/dados/conjuntos-dados/fiscalizacao-auto-de-infracao)

---

## ‚ú® Principais Funcionalidades

* **Pipeline de ETL Ass√≠ncrono (Crawler & Ingestion):** Um pipeline de dados completo, orquestrado via `cli.py`, que:
    1.  Baixa (crawls) o arquivo `.zip` de dados mais recente de forma ass√≠ncrona usando `httpx` (`CrawlerService`).
    2.  Processa os CSVs de grande volume em *chunks* (lotes) usando **Pandas**, garantindo baixo consumo de mem√≥ria.
    3.  Ingere os dados no MySQL de forma ass√≠ncrona (`IngestionService`).
* **Opera√ß√£o de Upsert Inteligente:** A l√≥gica de ingest√£o utiliza o `INSERT ... ON DUPLICATE KEY UPDATE` do MySQL (via `sqlalchemy.dialects.mysql.insert`), permitindo inserir novos registros e atualizar os existentes em uma √∫nica opera√ß√£o at√¥mica, garantindo a consist√™ncia dos dados.
* **API RESTful 'Async-First':** Todos os endpoints s√£o totalmente ass√≠ncronos (`async def`), desde a requisi√ß√£o web (FastAPI) at√© a consulta no banco de dados (SQLAlchemy 2.0 + `asyncmy`), garantindo alt√≠ssima concorr√™ncia e performance de I/O.
* **Autentica√ß√£o e Autoriza√ß√£o Segura:** Implementa√ß√£o de autentica√ß√£o baseada em tokens **JWT (JSON Web Tokens)** e um sistema de autoriza√ß√£o baseado em pap√©is (Roles: `ADMIN`, `USER`).
* **Configura√ß√£o Moderna com Dynaconf:** Gerenciamento de configura√ß√µes, usando `settings.toml` para padr√µes e `.secrets.toml` (git-ignored) para segredos e configura√ß√µes de ambiente.
* **Ambiente Containerizado e Reprodut√≠vel:** O projeto √© totalmente gerenciado pelo **Docker** e **Docker Compose**, orquestrando os containers da API, do banco de dados (MySQL) e do banco de testes.
* **Testes de Integra√ß√£o:** Su√≠te de testes automatizados usando `Pytest` e `httpx.AsyncClient`, que rodam contra um banco de dados de teste real e isolado para validar a API e a l√≥gica de neg√≥cio.

---

## üõ†Ô∏è Tecnologias Utilizadas

| Categoria | Tecnologia | Descri√ß√£o |
| :--- | :--- | :--- |
| **Backend** | **FastAPI** | Framework web de alta performance para constru√ß√£o de APIs ass√≠ncronas. |
| | **SQLAlchemy 2.0** | ORM para intera√ß√£o com o banco de dados, usando a nova sintaxe ass√≠ncrona (`AsyncSession`). |
| | **Pydantic V2** | Para valida√ß√£o, serializa√ß√£o de dados e gerenciamento de schemas da API. |
| | **Pandas** | Utilizado para o processamento eficiente (em *chunks*) de grandes arquivos CSV. |
| | **httpx** | Cliente HTTP ass√≠ncrono moderno, usado pelo Crawler para I/O de rede n√£o-bloqueante. |
| | **Typer** | Para cria√ß√£o do `cli.py`, o ponto de entrada do pipeline de ETL. |
| **Banco de Dados** | **MySQL 8.0** | Banco de dados relacional principal. |
| | **asyncmy** | Driver MySQL ass√≠ncrono, permitindo o uso de `await` em queries. |
| **Autentica√ß√£o** | **JWT / Passlib** | Para gera√ß√£o de tokens de acesso seguros e hashing de senhas. |
| **Tooling & DevOps** | **Docker & Docker Compose** | Para containeriza√ß√£o da aplica√ß√£o, banco de dados e ambiente de testes. |
| | **Alembic** | Ferramenta para gerenciamento de migra√ß√µes de schema do banco de dados. |
| | **Dynaconf** | Gerenciador de configura√ß√µes por ambiente. |
| | **Pytest** | Framework para testes de unidade e integra√ß√£o. |
| | **Uvicorn** | Servidor ASGI de alta performance para rodar a aplica√ß√£o FastAPI. |

---

## üöÄ Como Executar o Projeto

O projeto √© desenhado para ser executado **exclusivamente com Docker**. N√£o √© necess√°rio (nem recomendado) instalar depend√™ncias Python ou um banco de dados na sua m√°quina local.

### Pr√©-requisitos

* [**Docker**](https://www.docker.com/get-started) e [**Docker Compose**](https://docs.docker.com/compose/install/)
* (Recomendado) [VS Code](https://code.visualstudio.com/) com a extens√£o [Remote - Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers)

### 1. Clonar o Reposit√≥rio

```bash
git clone [https://github.com/luizvn/ibama_api.git](https://github.com/luizvn/ibama_api.git)
cd ibama_api
```

### 2. Configurar Vari√°veis de Ambiente

Este projeto usa o Docker Compose para injetar vari√°veis de ambiente no container da API a partir de um arquivo .env.
Crie um arquivo .env na raiz do projeto (este arquivo est√° no .gitignore e n√£o ser√° enviado ao reposit√≥rio).

**Arquivo: .env**
```env
# Configura√ß√µes do Banco de Dados (lidas pelo Docker Compose e pela API)
# Estas senhas devem bater com as do docker-compose.yml
DB_HOST=db
DB_PORT=3306
DB_USER=root
DB_PASS=root
DB_NAME=ibama_db

# String de conex√£o principal (usada pela API e Alembic)
# Deve usar o driver 'asyncmy' e apontar para o nome do servi√ßo 'db'
DATABASE_URL="mysql+asyncmy://root:root@db:3306/ibama_db"

# String de conex√£o de teste (usada pelo Pytest)
DATABASE_URL_TEST="mysql+asyncmy://root:root@db:3306/ibama_db_test"

# Chave secreta para assinar os tokens JWT
# Gere com: openssl rand -hex 32
SECRET_KEY="<sua_chave_secreta_de_32_bytes_aqui>"

# Configura√ß√µes do Token JWT
ALGORITHM="HS256"
ACCESS_TOKEN_EXPIRE_MINUTES=30
```

### 3. Iniciar o Ambiente Docker

Este comando ir√° construir a imagem da API (se ainda n√£o existir), iniciar o container da API e o container do banco de dados MySQL em segundo plano.

```bash
docker-compose up -d --build
```

Aguarde alguns segundos at√© que o banco de dados esteja totalmente inicializado (voc√™ pode verificar com docker-compose logs db).

### 4. Aplicar as Migra√ß√µes do Banco de Dados

Com os containers em execu√ß√£o, execute o Alembic dentro do container da API para criar as tabelas no banco.

```bash
docker-compose exec api alembic upgrade head
```

### 5. Aplicar as Migra√ß√µes do Banco de Dados
Com o banco de dados rodando e as depend√™ncias instaladas, aplique as migra√ß√µes para criar as tabelas:
```bash
alembic upgrade head
```
### 5. Criar um Usu√°rio Administrador

Para ter acesso aos endpoints administrativos (como o upload de CSV), voc√™ precisa de um usu√°rio `ADMIN`.

**Passo 1: Crie um usu√°rio via API**

Use a documenta√ß√£o interativa em `http://localhost:8000/docs` para enviar uma requisi√ß√£o `POST` para o endpoint `/users` ou utilize o comando `curl` abaixo no seu terminal.

```bash
curl -X POST "http://localhost:8000/users" \
-H "Content-Type: application/json" \
-d '{"username": "admin", "password": "Test@1234"}'
```
**Passo 2: Promova o usu√°rio para ADMIN**

Conecte-se ao seu banco de dados MySQL (usando DBeaver, DataGrip, ou o terminal do docker-compose) e execute o seguinte comando SQL para definir a `role` do usu√°rio rec√©m-criado como `ADMIN`.

```sql
UPDATE users SET role = 'ADMIN' WHERE username = 'admin';
```

### 6. Acessar a API

A API estar√° dispon√≠vel em `http://localhost:8000`.
A documenta√ß√£o interativa (Swagger UI) pode ser acessada em `http://localhost:8000/docs`.

### 7. (Opcional) Executar o Pipeline de ETL Manualmente

Voc√™ pode disparar o pipeline completo de crawler e ingest√£o executando o `cli.py` *dentro* do container da API:

```bash
docker-compose exec api python cli.py run
```

Isso iniciar√° o download do arquivo .zip, processamento e ingest√£o no banco.

---

## üèõÔ∏è Arquitetura e Decis√µes de Design

* **Estrutura de Projeto Limpa:** O c√≥digo √© organizado seguindo princ√≠pios de *separation of concerns*, dividindo a l√≥gica em camadas de `api` (routers), `services` (l√≥gica de neg√≥cio), `schemas` (contratos de dados Pydantic) e `models` (ORM SQLAlchemy).
* **Arquitetura 'Async-First':** A escolha por `async` de ponta-a-ponta (FastAPI, `httpx`, `asyncmy`) foi deliberada para maximizar a performance de I/O e a concorr√™ncia.
* **ETL como um Processo Separado (CLI):** O pipeline de ETL (`cli.py`) √© intencionalmente separado da API web (`app.main:app`). Isso evita que um processo de ingest√£o de dados longo e pesado trave ou consuma recursos do servidor web e tamb√©m posssa ser executado como um processo "cron" independente.
* **Configura√ß√£o com Dynaconf:** O `Dynaconf` foi escolhido por sua flexibilidade, permitindo um sistema de configura√ß√£o em camadas, onde `settings.toml` define padr√µes e vari√°veis de ambiente (lidas do `.env`) sobrescrevem com segredos.
* **Testes de Integra√ß√£o com Banco Real:** O `Pytest` (`conftest.py`) √© configurado para rodar testes de integra√ß√£o contra um banco de dados de teste real (criado pelo `docker-compose` e `01-create-test-db.sql`). Isso garante que nossas queries e l√≥gica de neg√≥cio funcionam como esperado no ambiente MySQL, indo al√©m de mocks.

---

## üë®‚Äçüíª Autor

**Luiz Vin√≠cius Souza**

* [LinkedIn](https://www.linkedin.com/in/luizvn/)
* [GitHub](https://github.com/luizvn)
